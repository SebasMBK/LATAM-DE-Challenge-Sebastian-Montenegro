{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data engineer challenge - Sebastian Montenegro\n",
    "Mi nombre es Sebastian Montenegro y en este notebook comentare sobre la resolucion del challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables e imports\n",
    "En la siguiente celda estare colocando las variables que seran utilizadas por las diferentes funciones del challenge y los imports de las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q1_memory import q1_memory\n",
    "from q1_time import q1_time\n",
    "from q2_memory import q2_memory\n",
    "from q2_time import q2_time\n",
    "from q3_memory import q3_memory\n",
    "from q3_time import q3_time\n",
    "\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suposiciones y comentarios\n",
    "- Para cada uno de los ejercicios estare considerando en el procesamiento de los datos solo los tweets originales y nos los quoted tweets, ya que esto generaria duplicados en los datos y alteraria las metricas reales.\n",
    "- El contexto de los tweets trata sobre las protestas de los granjeros/agricultores del pais de la India que ocurrio entre los años 2020 y 2021.\n",
    "- Durante el desarrollo de todos los ejercicios se busca evitar cargar todas las lineas por completo en memoria. Solo se usan los atributos/keys necesarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 - Solucion del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-Time\n",
    "\n",
    "#### Explicacion del codigo:\n",
    "1. Primero cargaremos toda la data en memoria.\n",
    "2. Realizaremos el procesamiento apoyandonos de la libreria pandas.\n",
    "3. Convertimos los timestamps en un formato reconocible para el procesamiento y nos quedaremos solo con la fecha\n",
    "4. Partiremos el proceso en 4 partes: Obtener el top 10 tweets por fecha, Obtener el conteo de tweets por usuario por fecha, Obtener el top usuario por cada fecha y, finalmente, realizar un join entre las top 10 fechas y el top usuario por fecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt1_time = q1_time(file_path=file_path)\n",
    "qt1_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-Memory\n",
    "\n",
    "#### Explicacion del codigo:\n",
    "1. Primero crearemos un generador que iterara sobre el archivo json y evitar cargar toda la data en memoria durante el procesamiento.\n",
    "2. Realizaremos el procesamiento apoyandonos de la libreria collection.\n",
    "3. Contaremos en un principio la cantidad de tweets por fecha.\n",
    "4. Contaremos la cantidad de tweets de cada usuario por fecha.\n",
    "5. Obtendremos el top 10 de fechas con mas tweets.\n",
    "6. Finalmente, obtendremos los usuarios con mas tweets por cada fecha comparando el punto 4 y 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt1_memory = q1_memory(file_path=file_path)\n",
    "qt1_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 - Solucion del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-Time\n",
    "\n",
    "#### Explicacion del codigo:\n",
    "1. Primero partimos el contenido del tweet en grafemas (una unidad minimas de escritura).\n",
    "2. Tomaremos todos los emojis que se encuentran en el contenido del tweet.\n",
    "3. Cargaremos toda esa data en memoria.\n",
    "4. Realizaremos el procesamiento apoyandonos de la libreria pandas.\n",
    "5. Contaremos la cantidad total de cada emoji que se encuentra en la data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt2_time = q2_time(file_path=file_path)\n",
    "qt2_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-Memory\n",
    "\n",
    "#### Explicacion del codigo:\n",
    "1. Primero crearemos el extractor de emojis que toma un string y lo separa por grafemas. Este extractor es un generator lo que nos permite evitar cargar toda la data en memoria.\n",
    "2. Luego crearemos un contador de emojis que se apoyara del punto 1 y utilizara Counter de la libreria collections para este proposito.\n",
    "3. Tomaremos los 10 emojis mas comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt2_memory = q2_memory(file_path=file_path)\n",
    "qt2_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 - Solucion del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3-Time\n",
    "\n",
    "#### Explicacion del codigo:\n",
    "1. Primero cargaremos toda la data relacionada a las menciones en memoria.\n",
    "2. Debido a que lo que obtenemos es un array de arrays buscamos utilizar el metodo \"extend\" de las listas de python para hacer un \"flatten\" de los mismos.\n",
    "3. Realizaremos el procesamiento apoyandonos de la libreria pandas.\n",
    "4. Contaremos todas las ocurrencias de cada mencion y nos quedaremos con el top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt3_time = q3_time(file_path=file_path)\n",
    "qt3_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3-Memory\n",
    "\n",
    "#### Explicacion del codigo:\n",
    "1. Primero crearemos un generador que iterara sobre el archivo json y evitar cargar toda la data en memoria durante el procesamiento.\n",
    "2. Realizaremos el procesamiento apoyandonos de la libreria collection.\n",
    "3. En caso existan menciones en el tweet las contaremos.\n",
    "4. De dicha cuenta total tomaremos el top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt3_memory = q3_memory(file_path=file_path)\n",
    "qt3_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejoras y comentarios generales\n",
    "- Se esta considerando cargar toda la data en memoria y procesarla en los problemas de tipo TIME, ya que el procesar data que se encuentra cargada en la memoria deberia ser mas rapido\n",
    "- Una mejora a los problemas de tipo TIME es utilizar procesamiento distribuido o paralelismo (librerias como concurrent o polars) para alcanzar una mayor rapidez.\n",
    "- Para los problemas de tipo MEMORY seria util considerar el uso de lazy evaluation (librerias como polars) que solo evaluen el procesamiento cuando sea necesario y evitar cargar data innecesaria en memoria lo que permitiria un mejor escalamiento.\n",
    "- Es ideal contar con un correcto manejo de logs de errores en nuestro pipeline, por lo que se deberian remplazar los prints de errores con un sistema propio de logging.\n",
    "- Los datos deben poder ser confiables, por lo que es necesario añadir un sistema de quality control que puede ser implementado con librerias como pydantic, great expectations, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
